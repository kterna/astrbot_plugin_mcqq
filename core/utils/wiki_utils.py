import asyncio
import re
import aiohttp
from typing import Optional, Dict, Any
from astrbot import logger


class WikiUtils:
    """Minecraft Wiki å·¥å…·ç±»"""
    
    BASE_API_URL = "https://zh.minecraft.wiki/api.php"
    
    @staticmethod
    async def get_random_wiki_content() -> Optional[str]:
        """
        ä»Minecraft Wikiéšæœºè·å–ä¸€ä¸ªè¯æ¡
        
        Returns:
            Optional[str]: æ ¼å¼åŒ–çš„wikiå†…å®¹ï¼Œæ ¼å¼ä¸º"ä½ çŸ¥é“å—ï¼š{title} - {content}"ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        api_url = f"{WikiUtils.BASE_API_URL}?action=query&prop=extracts&exintro=true&format=json&generator=random&grnnamespace=0&grnlimit=1"
        
        try:
            data = await WikiUtils._make_wiki_request(api_url)
            if not data:
                return None
            
            # è§£æéšæœºè¯æ¡è¿”å›çš„JSONæ•°æ®
            pages = data.get("query", {}).get("pages", {})
            if not pages:
                logger.warning("Wiki APIè¿”å›çš„æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°é¡µé¢")
                return None
            
            # è·å–ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€çš„ï¼‰é¡µé¢
            page_id = next(iter(pages.keys()))
            page_data = pages[page_id]
            
            title = page_data.get("title", "æœªçŸ¥æ ‡é¢˜")
            extract = page_data.get("extract", "")
            
            if not extract:
                logger.warning(f"Wikié¡µé¢ {title} æ²¡æœ‰æ‘˜è¦å†…å®¹")
                return None
            
            # æ¸…ç†HTMLå¹¶æ ¼å¼åŒ–å†…å®¹
            clean_content = WikiUtils._clean_html_and_format(extract, max_length=200)
            
            # æ ¼å¼åŒ–è¿”å›å†…å®¹
            formatted_content = f"ä½ çŸ¥é“å—ï¼š{title} - {clean_content}"
            
            logger.debug(f"æˆåŠŸè·å–Wikiè¯æ¡: {title}")
            return formatted_content
            
        except Exception as e:
            logger.error(f"è·å–éšæœºWikiå†…å®¹æ—¶å‡ºé”™: {str(e)}")
            return None
    
    @staticmethod
    async def get_wiki_content_by_title(title: str) -> Optional[str]:
        """
        æ ¹æ®æ ‡é¢˜ä»Minecraft Wikiè·å–è¯æ¡å†…å®¹
        
        Args:
            title: è¦æœç´¢çš„è¯æ¡æ ‡é¢˜
            
        Returns:
            Optional[str]: æ ¼å¼åŒ–çš„wikiå†…å®¹ï¼Œå¤±è´¥æ—¶è¿”å›é”™è¯¯ä¿¡æ¯
        """
        api_url = f"{WikiUtils.BASE_API_URL}?action=query&prop=extracts&exintro=true&format=json&titles={title}"
        
        try:
            data = await WikiUtils._make_wiki_request(api_url)
            if not data:
                return "Wikiè¯·æ±‚å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
            
            # è§£ææŒ‡å®šæ ‡é¢˜è¿”å›çš„JSONæ•°æ®
            pages = data.get("query", {}).get("pages", {})
            if not pages:
                logger.warning("Wiki APIè¿”å›çš„æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°é¡µé¢")
                return f"æœªæ‰¾åˆ°è¯æ¡ï¼š{title}"
            
            # è·å–ç¬¬ä¸€ä¸ªé¡µé¢
            page_id = next(iter(pages.keys()))
            page_data = pages[page_id]
            
            # æ£€æŸ¥é¡µé¢æ˜¯å¦å­˜åœ¨ï¼ˆpage_idä¸º-1è¡¨ç¤ºé¡µé¢ä¸å­˜åœ¨ï¼‰
            if page_id == "-1":
                return f"æœªæ‰¾åˆ°è¯æ¡ï¼š{title}"
            
            page_title = page_data.get("title", title)
            extract = page_data.get("extract", "")
            
            if not extract:
                return f"è¯æ¡ {page_title} æ²¡æœ‰å¯ç”¨çš„å†…å®¹æ‘˜è¦"
            
            # æ¸…ç†HTMLå¹¶æ ¼å¼åŒ–å†…å®¹
            clean_content = WikiUtils._clean_html_and_format(extract, max_length=200)
            
            # æ ¼å¼åŒ–è¿”å›å†…å®¹
            formatted_content = f"ğŸ“– {page_title}: {clean_content}"
            
            logger.debug(f"æˆåŠŸè·å–Wikiè¯æ¡: {page_title}")
            return formatted_content
            
        except Exception as e:
            logger.error(f"è·å–Wikiå†…å®¹æ—¶å‡ºé”™: {str(e)}")
            return f"è·å–Wikiå†…å®¹æ—¶å‡ºé”™: {str(e)}"
    
    @staticmethod
    async def _make_wiki_request(url: str) -> Optional[Dict[str, Any]]:
        """
        å‘é€Wiki APIè¯·æ±‚
        
        Args:
            url: APIè¯·æ±‚URL
            
        Returns:
            Optional[Dict[str, Any]]: JSONå“åº”æ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=10) as response:
                    if response.status != 200:
                        logger.error(f"Wiki APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
                    
                    return await response.json()
                    
        except asyncio.TimeoutError:
            logger.error("Wiki APIè¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"Wiki APIè¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
            return None
    
    @staticmethod
    def _clean_html_and_format(html_text: str, max_length: int = 200) -> str:
        """
        æ¸…ç†HTMLæ ‡ç­¾å¹¶æ ¼å¼åŒ–æ–‡æœ¬
        
        Args:
            html_text: åŒ…å«HTMLæ ‡ç­¾çš„æ–‡æœ¬
            max_length: æœ€å¤§é•¿åº¦é™åˆ¶
            
        Returns:
            str: æ¸…ç†åçš„çº¯æ–‡æœ¬
        """
        # ç§»é™¤HTMLæ ‡ç­¾
        clean_text = re.sub('<[^<]+?>', '', html_text)
        
        # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        
        # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…è¿‡é•¿
        if len(clean_text) > max_length:
            clean_text = clean_text[:max_length] + "..."
        
        return clean_text 